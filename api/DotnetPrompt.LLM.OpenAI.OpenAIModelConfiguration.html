<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Class OpenAIModelConfiguration
 | DotnetPrompt </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Class OpenAIModelConfiguration
 | DotnetPrompt ">
    <meta name="generator" content="docfx ">
  
    <link rel="shortcut icon" href=".././images/logo.svg">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> 
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
  
  <meta property="docfx:rel" content="../">
  
  </head>  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>

        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>

              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src=".././images/logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>

        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">

        <div id="search-results">
          <div class="search-list">Search Results for <span></span></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination" data-first="First" data-prev="Previous" data-next="Next" data-last="Last"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">

        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration">


  <h1 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration" class="text-break">Class OpenAIModelConfiguration
</h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="inheritance">
    <h5>Inheritance</h5>
    <div class="level0"><span class="xref">object</span></div>
    <div class="level1"><span class="xref">OpenAIModelConfiguration</span></div>
      <div class="level2"><a class="xref" href="DotnetPrompt.LLM.OpenAI.ChatGptModelConfiguration.html">ChatGptModelConfiguration</a></div>
  </div>
  <div class="implements">
    <h5>Implements</h5>
    <div><span class="xref">IEquatable</span>&lt;<a class="xref" href="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.html">OpenAIModelConfiguration</a>&gt;</div>
  </div>
  <div class="inheritedMembers">
    <h5>Inherited Members</h5>
    <div>
      <span class="xref">object.Equals(object)</span>
    </div>
    <div>
      <span class="xref">object.Equals(object, object)</span>
    </div>
    <div>
      <span class="xref">object.GetHashCode()</span>
    </div>
    <div>
      <span class="xref">object.GetType()</span>
    </div>
    <div>
      <span class="xref">object.MemberwiseClone()</span>
    </div>
    <div>
      <span class="xref">object.ReferenceEquals(object, object)</span>
    </div>
    <div>
      <span class="xref">object.ToString()</span>
    </div>
  </div>
  <h6><strong>Namespace</strong>: <span class="xref">DotnetPrompt</span>.<span class="xref">LLM</span>.<a class="xref" href="DotnetPrompt.LLM.OpenAI.html">OpenAI</a></h6>
  <h6><strong>Assembly</strong>: DotnetPrompt.LLM.OpenAI.dll</h6>
  <h5 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public record OpenAIModelConfiguration : IEquatable&lt;OpenAIModelConfiguration&gt;</code></pre>
  </div>
  <h3 id="fields">Fields
</h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Default.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Default%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L11">View Source</a>
  </span>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Default" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Default">Default</h4>
  <div class="markdown level1 summary"><p>Default model configuration</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public static OpenAIModelConfiguration Default</code></pre>
  </div>
  <h5 class="fieldValue">Field Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.html">OpenAIModelConfiguration</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="properties">Properties
</h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_CacheLevel.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.CacheLevel%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L124">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_CacheLevel_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.CacheLevel*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_CacheLevel" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.CacheLevel">CacheLevel</h4>
  <div class="markdown level1 summary"><p>can be used to disable any server-side caching, 0=no cache, 1=prompt prefix
enabled, 2=full cache</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;cache_level&quot;)]
public int? CacheLevel { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">int</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_CompletionConfig.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.CompletionConfig%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L117">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_CompletionConfig_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.CompletionConfig*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_CompletionConfig" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.CompletionConfig">CompletionConfig</h4>
  <div class="markdown level1 summary"><p>Completion configuration.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;completion_config&quot;)]
public string CompletionConfig { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">string</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Echo.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Echo%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L109">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Echo_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Echo*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Echo" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Echo">Echo</h4>
  <div class="markdown level1 summary"><p>Echo back the prompt in addition to the completion.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;echo&quot;)]
public bool? Echo { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">bool</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_FrequencyPenalty.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.FrequencyPenalty%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L139">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_FrequencyPenalty_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.FrequencyPenalty*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_FrequencyPenalty" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.FrequencyPenalty">FrequencyPenalty</h4>
  <div class="markdown level1 summary"><p>How much to penalize new tokens based on whether they appear in the text so
far. Increases the model's likelihood to talk about new topics.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;frequency_penalty&quot;)]
public float? FrequencyPenalty { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">float</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_GenerationSampleCount.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.GenerationSampleCount%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L55">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_GenerationSampleCount_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.GenerationSampleCount*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_GenerationSampleCount" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.GenerationSampleCount">GenerationSampleCount</h4>
  <div class="markdown level1 summary"><p>How many generations to create server side, and display only the best. Will not
stream intermediate progress if best_of &gt; 1. Has maximum value of 128.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;best_of&quot;)]
public int? GenerationSampleCount { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">int</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_LogitBias.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.LogitBias%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L97">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_LogitBias_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.LogitBias*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_LogitBias" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.LogitBias">LogitBias</h4>
  <div class="markdown level1 summary"><p>Defaults to null. Modify the likelihood of specified tokens appearing in the
completion. Accepts a json object that maps tokens (specified by their token ID
in the GPT tokenizer) to an associated bias value from -100 to 100. You can use
this tokenizer tool (which works for both GPT-2 and GPT-3) to convert text to
token IDs. Mathematically, the bias is added to the logits generated by the
model prior to sampling. The exact effect will vary per model, but values
between -1 and 1 should decrease or increase likelihood of selection; values
like -100 or 100 should result in a ban or exclusive selection of the relevant
token. As an example, you can pass {&quot;50256&quot; &amp;#58; -100} to prevent the
&lt;|endoftext|&gt; token from being generated.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;logit_bias&quot;)]
public IDictionary&lt;string, int&gt; LogitBias { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">IDictionary</span>&lt;<span class="xref">string</span>, <span class="xref">int</span>&gt;</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_LogProbability.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.LogProbability%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L48">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_LogProbability_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.LogProbability*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_LogProbability" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.LogProbability">LogProbability</h4>
  <div class="markdown level1 summary"><p>Include the log probabilities on the <code>logprobs</code> most likely tokens, as well the
chosen tokens. So for example, if <code>logprobs</code> is 10, the API will return a list
of the 10 most likely tokens. If <code>logprobs</code> is 0, only the chosen tokens will
have logprobs returned. Minimum of 0 and maximum of 100 allowed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;logprobs&quot;)]
public int? LogProbability { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">int</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_MaxTokens.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.MaxTokens%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L72">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_MaxTokens_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.MaxTokens*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_MaxTokens" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.MaxTokens">MaxTokens</h4>
  <div class="markdown level1 summary"><p>The maximum number of tokens to generate. Has minimum of 0.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;max_tokens&quot;)]
public int? MaxTokens { get; set; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">int</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h5 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_MaxTokens_remarks">Remarks</h5>
  <div class="markdown level1 remarks"><p>Could be set to -1 if there a single prompt to return as many tokens as possible given the prompt and the models maximal context size.</p>
</div>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Model.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Model%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L105">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Model_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Model*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Model" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Model">Model</h4>
  <div class="markdown level1 summary"><p>The name of the model to use.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;model&quot;)]
public string Model { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">string</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_NucleusSamplingFactor.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.NucleusSamplingFactor%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L32">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_NucleusSamplingFactor_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.NucleusSamplingFactor*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_NucleusSamplingFactor" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.NucleusSamplingFactor">NucleusSamplingFactor</h4>
  <div class="markdown level1 summary"><p>An alternative to sampling with temperature, called nucleus sampling, where the
model considers the results of the tokens with top_p probability mass. So 0.1
means only the tokens comprising the top 10% probability mass are
considered.
We generally recommend using this or <code>temperature</code> but not
both.
Minimum of 0 and maximum of 1 allowed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;top_p&quot;)]
public float? NucleusSamplingFactor { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">float</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_PresencePenalty.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.PresencePenalty%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L132">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_PresencePenalty_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.PresencePenalty*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_PresencePenalty" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.PresencePenalty">PresencePenalty</h4>
  <div class="markdown level1 summary"><p>How much to penalize new tokens based on their existing frequency in the text
so far. Decreases the model's likelihood to repeat the same line verbatim. Has
minimum of -2 and maximum of 2.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;presence_penalty&quot;)]
public float? PresencePenalty { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">float</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Prompt.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Prompt%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L67">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Prompt_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Prompt*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Prompt" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Prompt">Prompt</h4>
  <div class="markdown level1 summary"><p>An optional prompt to complete from, encoded as a string, a list of strings, or
a list of token lists. Defaults to &lt;|endoftext|&gt;. The prompt to complete from.
If you would like to provide multiple prompts, use the POST variant of this
method. Note that &lt;|endoftext|&gt; is the document separator that the model sees
during training, so if a prompt is not specified the model will generate as if
from the beginning of a new document. Maximum allowed size of string list is
2048.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;prompt&quot;)]
public IList&lt;string&gt; Prompt { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">IList</span>&lt;<span class="xref">string</span>&gt;</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_SnippetCount.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.SnippetCount%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L39">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_SnippetCount_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.SnippetCount*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_SnippetCount" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.SnippetCount">SnippetCount</h4>
  <div class="markdown level1 summary"><p>How many snippets to generate for each prompt. Minimum of 1 and maximum of 128
allowed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;n&quot;)]
public int? SnippetCount { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">int</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Stop.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Stop%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L113">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Stop_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Stop*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Stop" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Stop">Stop</h4>
  <div class="markdown level1 summary"><p>A sequence which indicates the end of the current document.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;stop&quot;)]
public IList&lt;string&gt; Stop { get; set; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">IList</span>&lt;<span class="xref">string</span>&gt;</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Temperature.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Temperature%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L82">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Temperature_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Temperature*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_Temperature" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.Temperature">Temperature</h4>
  <div class="markdown level1 summary"><p>What sampling temperature to use. Higher values means the model will take more
risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones
with a well-defined answer.
We generally recommend using this or <code>top_p</code> but
not both.
Minimum of 0 and maximum of 2 allowed.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;temperature&quot;)]
public float? Temperature { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">float</span>?</td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_User.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.User%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L101">View Source</a>
  </span>
  <a id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_User_" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.User*"></a>
  <h4 id="DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration_User" data-uid="DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration.User">User</h4>
  <div class="markdown level1 summary"><p>The ID of the end-user, for use in tracking and rate-limiting.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="declaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">[JsonPropertyName(&quot;user&quot;)]
public string User { get; init; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">string</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="implements">Implements</h3>
  <div>
      <span class="xref">System.IEquatable&lt;T&gt;</span>
  </div>
</article>
          </div>

          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/xakpc/DotnetPrompt/new/main/apiSpec/new?filename=DotnetPrompt_LLM_OpenAI_OpenAIModelConfiguration.md&amp;value=---%0Auid%3A%20DotnetPrompt.LLM.OpenAI.OpenAIModelConfiguration%0Asummary%3A%20&#39;*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax&#39;%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A" class="contribution-link">Improve this Doc</a>
                  </li>
                  <li>
                    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/src/DotnetPrompt.LLM.OpenAI/OpenAIModelConfiguration.cs/#L6" class="contribution-link">View Source</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>

      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
      <span>Copyright 2023 © Pavel <i>«xakpc»</i> Osadchuk for <strong>DotnetPrompt</strong></span>
      
          </div>
        </div>
      </footer>
    </div>

    <script type="text/javascript" src="../styles/docfx.vendor.min.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
