<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Key Concepts | DotnetPrompt </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Key Concepts | DotnetPrompt ">
    <meta name="generator" content="docfx ">
  
    <link rel="shortcut icon" href="../.././images/logo.svg">
    <link rel="stylesheet" href="../../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../../styles/docfx.css">
    <link rel="stylesheet" href="../../styles/main.css">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet"> 
    <meta property="docfx:navrel" content="../../toc.html">
    <meta property="docfx:tocrel" content="../toc.html">
  
  <meta property="docfx:rel" content="../../">
  
  </head>  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>

        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>

              <a class="navbar-brand" href="../../index.html">
                <img id="logo" class="svg" src="../.././images/logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>

        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">

        <div id="search-results">
          <div class="search-list">Search Results for <span></span></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination" data-first="First" data-prev="Previous" data-next="Next" data-last="Last"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">

        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="">
<h1 id="key-concepts">Key Concepts</h1>

<h2 id="large-language-models">Large Language Models</h2>
<p>DotnetPrompt offers a layer, or multiple layers of abstraction over Large Language Models (LLMs), with a specific emphasis on their &quot;generate&quot; capability.
The central feature of our model abstraction is the <code>GenerateAsync</code> method, which generates an <code>ModelResult</code> that includes the outputs for each string in the input list.</p>
<p>Each LLM is an implementation of <code>ILargeLanguageModel</code> and inherits from <code>BaseModel</code>, which provides caching and resilience.</p>
<pre><code class="lang-charp">public interface ILargeLanguageModel
{
    /// &lt;summary&gt;
    /// Run the LLM on the given prompts and stops.
    /// &lt;/summary&gt;
    /// &lt;param name=&quot;prompts&quot;&gt;&lt;/param&gt;
    /// &lt;param name=&quot;stop&quot;&gt;&lt;/param&gt;
    /// &lt;returns&gt;&lt;/returns&gt;
    /// &lt;exception cref=&quot;InvalidOperationException&quot;&gt;When cache asked without &lt;/exception&gt;
    Task&lt;ModelResult&gt; GenerateAsync(IList&lt;string&gt; prompts, IList&lt;string&gt; stop = null);

    /// &lt;summary&gt;
    /// Keyword for model type, used for serialization
    /// &lt;/summary&gt;
    string LLMType { get; }
}
</code></pre>
<h2 id="modelresult">ModelResult</h2>
<p>The full output of a call to the <code>GenerateAsync</code> method of the model class. Since the <code>GenerateAsync</code> method takes as input a list of strings,
this returns a list of results. Each result consists of a list of generations (since you could request N generations per input string).
This also contains an <code>Output</code> attribute which contains provider-specific information about the call.</p>
<pre><code class="lang-csharp">/// &lt;summary&gt;
/// Class that contains all relevant information for an LLM Result.
/// &lt;/summary&gt;
public record ModelResult
{
    /// &lt;summary&gt;
    /// List of the things generated.
    /// This is List[List[]] because each input could have multiple generations/generated completions.
    /// &lt;/summary&gt;
    public IList&lt;IList&lt;Generation&gt;&gt; Generations { get; set; }

    /// &lt;summary&gt;
    /// For arbitrary LLM provider specific output.
    /// &lt;/summary&gt;
    public IDictionary&lt;string, object&gt; Output { get; set; }
}
</code></pre>
<h2 id="caching-wip">Caching (WIP)</h2>
<p>Usually, there is a cost associated with calling a model.
However, if you need to call the model multiple times with the same input, you can opt for the caching option to save money.</p>
<p>Constructor ov every model has a <code>IDistributedCache</code> option and <code>UseCache</code> property.</p>
<pre><code class="lang-csharp">BaseModel(ILogger logger, IDistributedCache cache)
</code></pre>
<p>By setting both - cache to <code>MemoryCahche</code> for example and property to true you will enable cache that will produce the same result for the same input and model configuration.</p>
<h2 id="resilience-wip">Resilience (WIP)</h2>
<p>We plan to use <a href="https://github.com/App-vNext/Polly">Polly</a> to ensure that requests to LLM always completed sucessfully.</p>
</article>
          </div>

          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/xakpc/DotnetPrompt/blob/main/docs/articles/llms/key_concepts.md/#L1" class="contribution-link">Improve this Doc</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
                <h5>In This Article</h5>
                <div></div>
              </nav>
            </div>
          </div>
        </div>
      </div>

      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
      <span>Copyright 2023 © Pavel <i>«xakpc»</i> Osadchuk for <strong>DotnetPrompt</strong></span>
      
          </div>
        </div>
      </footer>
    </div>

    <script type="text/javascript" src="../../styles/docfx.vendor.min.js"></script>
    <script type="text/javascript" src="../../styles/docfx.js"></script>
    <script type="text/javascript" src="../../styles/main.js"></script>
  </body>
</html>
